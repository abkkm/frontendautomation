https://www.youtube.com/watch?v=q2ynYUkVWnY&list=PLF5kUO89mjNqNzTG8NvQWjqS7EGlDvGUs&index=2

Reactive programming
Keeps main thread free.
Back pressure on data streams.
App more response.


1. Took the customer's oder
2. Told cook for prepare order
3. Waited for the food to be cooked
4. Gave it to thte customer
5. After all of that, then took the next person's order
which is sysnchronous


1. TAke a customers order
2. Tell the cook to prepare food.
3. Instead of waiting for it to be cooked, take next persoons order and list for(subscribe to) the cook to tell you the first cusomer's food is done.
4. Once the food is done, you give the food to the customer
reactive - asynchronous and non-blocking

when any data changes iin db, it will fire/publish the event. whoever subsribes can stream that data.



Reactive Rest API vs Traditional Rest API

Building Reactive Rest API

Spring Webflux

Webclient * WebTestClient


Traditional rest api -

databases blocking call - 1 ms
rest sysnchronous and blocking call - 1 ms

api takes 2 ms to serve the client request.

A thread will be assigned to a thread which makes database call or API call

the thread per request When the client requests execute thread pool we need to do horizonatal scaling (increase instances)

no back pressure support when client requests are more.


We can make asyncrouns and non blcking using reactive rest apis.

Reactive programming
data flows as an event driven stream which is known as reactive stream.

reactive stream specification

it is created by netflix and pivotal.

It has 4 interfaces.

* Publisher - subscribe
* Subscriber - onsubscribe, onnext, onerror, oncomplete
* Subscription - request, cancel
* Processor - extends both publishser and Subscriber

Publisher is a data source who will always publish an event.
Susbcription represents the unique relationship between a subscriber and a publisher
A processor represents a processing stage - which is both a subscriber and a publisher and must obey the contracts of noth.

Reactive programming libary

* Reactor
* RxJava
* Jdk9 Flow Reactive Stream

Plugins

--Spring assistant

Dependencies(nly one dep is needed)

-Spring Reactive Web

Publisher - subscriber

Publichser - emits the data, Consumer consumes the data

1. subsciber()
subsription
request(n)
4orderNext(Data)
4.1 onNext(data)
...
4.n onNext(data)
oncomplete()

Dependencies

dao - publishser
browser - subscriber

When the subsciber cancels the request. It immediately stops the executioin. But in traditionl approach it coninues execution.

REst API - Controller - Service

Funcation Endpoint - Router - Handler

How to write functional Endpoint

return ServerResponse.ok().
                contentType(MediaType.TEXT_EVENT_STREAM) // data send as stream not object

                
                write all CRUD operations in service class
                ----------------------------

requestForData ()
request(n)
onNext(1), onNext(2),....onNext(n)
onComplete()

No more blocking call
They are realease to do other work.

Reactive programmiing
-EVent/message driven
Functional code style
Baclk pressure on data streams.

https://github.com/shabbirdwd53/reactive-programming-tutorial

https://projectreactor.io/

Netty as non blocking server.

Publisher(Database, server,..) - It will send the data.

OnNext method publisher emits the data using Subscription object.

Mono works with one element
Flux works with multiple elements


Spring reactive uess java reactive library.

We can do opertions on the returned data using operators

After error flux will not stream any data.

Map convert one type to another type

flapMap converts from Mono<String> to Mono<List<String>>
concapMap will preserve the order of the elements
flapMapMany - wants to performs operations on mono return flux (Convets mono of objects(string) to flux of objects)
transforms - converts one type to another type
filter data we can use multipe places

defaultIfEmpty - if no data pass the default
switchIfEmpty - gives 

combines different streams

concat - comibens multipe publibers
concat - static
concatwith - with instance

merge - comibens multipe publibers( not in sequential manner) - Not wait for the publisher to complete
merge - static
mergewith - with instance


mergeSequential - Emits teh data in sequential order

upto we saw same type ( result)
--------------

Zip, ZipWith - Works with different types
(result is different)

doOnNext
doOnSubscribe
doOnComplete

------------

1. handle the error
2. Resume on the error

onErrorReturn - Sends the default value.
OnErrorContinue

onErrorMap - Throwable (Maps runtime exp to throwable)

doOnError operators - same as try catch

retry, retry(n) - 

retry - undefinte try
retry - limited try

retryWhen - retry for particul call(db ,api)


backpressure buffer - keeps the data in buffer

Cold stream - same set of data (hhtp call...)
Hot stream - gets the data at a time interval(sports qote, stock quote)

The StepVerifier is central to testing all things reactive. It gives us a way to assert that what we think is going to come next in the publisher is in fact going to come next in the publisher. The StepVerifier provides several variants on the expect* theme. Think of this as the reactive equivalent to Assert*.

Conclusion
doOnNext works only when data is available and doOnSuccess works with or without data.
doOnNext and doOnSuccess should be used for logging and not updating some values as doOnNext or any of the doOn* methods are NOT subscribing to publishers.


fromiterable - fromlist to create flux or mono

after subsbibe the publisher emits the data.

tranform - converts none type to another type(accepts functional interface as input)

if no data to be emitted - defaultIfEmpyt("Default")
if want to different data - switchIfEmpyt()

concat - with static - (11,12,21,22)
contactwith  - with instance  - (executes in sequential order) 

.delayEletments - emits the data in the different time rate.

mergewith  - (11,21,12, 22)
mergesequential  -  (11,12,21,22) -  (executes in sequential order) 

Zip - 11+21, 12+22 (max 8 sources) - returns tuple
Zipwith 

doon operator - sideeffect - actual behavior dont change., dosuccess, doOnComplete,doOnSubscribe,doOnNext,...

error - when error occurs. the publisher stops emitting the data and sends the error data.

there are two ways to handle the exceptions in reactive streams.

onErrorReturn - Send the default value.

OnErrorContinue - drops the error data and contines another data

onErrorMap - Converts exception to a custom exception.
donOnError - same as try cathc

@Data
@AllArgsconstructor
@NoArgcontructor

flapMap - Flattening the object
retry - retry when there is an exception
retry(3) - retry with 3 times after the first attempt.
retrywhen() - 
backoff - retry interval

-----

backpressure : suppose my publisher emits 100 data whicah can not be handled b my subscriber.


backpressuredrop : handles dropped data.

backpressurebuffer : keeps some data on the buffer

Hot stream : only current data

Cold starem : current data + old data

Debug :

Option 1:

Hooks.onOperatorDebug();

Option 2: Add checkpoint

.map()
.checkpoint("Error Checkpoint")

Option 3: 

add 

reactive-tools depen

ReactorDebugAgent.init(); 
ReactorDebugAgent.processExistingClasses();
in main class


-----------------

sink can act as both publisher and subsciber

Stream events(server side events) from backend to frontend

One way communication

mulitple thread emits mulitple items via the sink.

--

Order Service - Spring data JPA

product service - nosql - Spring Data Reactive Mongo

User service - rdbms - R2DBC - reactive driver for relational db
-----

Whenever you use mongodb empbe

BeanUtils - Convert dto to entity


---

For data server.
Here we are using subscribe method.
But in controller we return publisher.

----

Use flatMap when mono within mono

-----

        return this.service.getUserById(id)
                    .map(ResponseEntity::ok) // if user is present
                    .defaultIfEmpty(ResponseEntity.notFound().build()); //if user is not found

                    -----------



    

---------------Start of second time----

doOnSubscribe method the publisher sends the subscription event
1
 Mono<String> monoString = Mono.just("java");
 monoString.Susbcribe(System.out::println);
 2
  Mono<String> monoString = Mono.just("java").log();
 monoString.Susbcribe(System.out::println);
 3
   Mono<String> monoString = Mono.just("java")
   .then(Mono.error(new RuntimeException("Exception occured"))
   .log();
 monoString.Susbcribe(System.out::println);
  4
   Mono<String> monoString = Mono.just("java")
   .then(Mono.error(new RuntimeException("Exception occured"))
   .log();
 monoString.Susbcribe(System.out::println, (e)->System.out.println(e.getMessage()));

 5
Flux<String> fluxString = Flux.just("Java", "Spring").log();
 fluxString.Susbcribe(System.out::println);
 6
Flux<String> fluxString = Flux.just("Java", "Spring")
.concatWithValues("AWS")
.log();
 fluxString.Susbcribe(System.out::println);
  7
Flux<String> fluxString = Flux.just("Java", "Spring")
.concatWithValues("AWS")
   .concatWith(Flux.error(new RuntimeException("Exception occured"))
.log();
 fluxString.Susbcribe(System.out::println, (e)->System.out.println(e.getMessage()));
  8
Flux<String> fluxString = Flux.just("Java", "Spring")
.concatWithValues("AWS")
   .concatWith(Flux.error(new RuntimeException("Exception occured"))
   .concatWithValues("Cloud")
.log();
 fluxString.Susbcribe(System.out::println, (e)->System.out.println(e.getMessage()));

 9

         return IntStream.rangeClosed(1, 50)
                .peek(CustomerDao::sleepExecution)
                .peek(i -> System.out.println("processing count : " + i))
                .mapToObj(i -> new Customer(i, "customer" + i))
                .collect(Collectors.toList());

10

    public Flux<Customer> getCustomersStream()  {
        return Flux.range(1,10)
                .delayElements(Duration.ofSeconds(1))
                .doOnNext(i -> System.out.println("processing count in stream flow : " + i))
                .map(i -> new Customer(i, "customer" + i));
    }

 if error occurs onError will be called.
 if all data emitted then onComplete will ne called.

doOnmethods - side effects


Flux<String> fluxString = Flux.just("Java", "Spring").log();

sub

Rest API - Controller - service
Functional Endpoint - Router - Handler


@Configuration
public class RouterConfig {

    @Autowired
    private CustomerHandler handler;

    @Autowired
    private CustomerStreamHandler streamHandler;

    @Bean
    public RouterFunction<ServerResponse> routerFunction(){
        return RouterFunctions.route()
                .GET("/router/customers",handler::loadCustomers)
                .GET("/router/customers/stream",streamHandler::getCustomers)
                .GET("/router/customer/{input}",handler::findCustomer)
                .POST("/router/customer/save",handler::saveCustomer)
                .build();

    }
}
--------
@Service
public class CustomerHandler {

    @Autowired
    private CustomerDao dao;


    public Mono<ServerResponse> loadCustomers(ServerRequest request){
        Flux<Customer> customerList = dao.getCustomerList();
        return ServerResponse.ok().body(customerList,Customer.class);
    }


    public Mono<ServerResponse> findCustomer(ServerRequest request){
      int customerId= Integer.valueOf( request.pathVariable("input"));
       // dao.getCustomerList().filter(c->c.getId()==customerId).take(1).single();
        Mono<Customer> customerMono = dao.getCustomerList().filter(c -> c.getId() == customerId).next();
        return ServerResponse.ok().body(customerMono,Customer.class);
    }


    public Mono<ServerResponse> saveCustomer(ServerRequest request){
        Mono<Customer> customerMono = request.bodyToMono(Customer.class);
        Mono<String> saveResponse = customerMono.map(dto -> dto.getId() + ":" + dto.getName());
        return ServerResponse.ok().body(saveResponse,String.class);
    }



}

---------
@Service
public class CustomerStreamHandler {

    @Autowired
    private CustomerDao dao;


    public Mono<ServerResponse> getCustomers(ServerRequest request) {
        Flux<Customer> customersStream = dao.getCustomersStream();
        return ServerResponse.ok().
                contentType(MediaType.TEXT_EVENT_STREAM) // data send as stream not object
                .body(customersStream, Customer.class);
    }
}


-----
@Service
public class CustomerHandler {

    @Autowired
    private CustomerDao dao;


    public Mono<ServerResponse> loadCustomers(ServerRequest request){
        Flux<Customer> customerList = dao.getCustomerList();
        return ServerResponse.ok().body(customerList,Customer.class);
    }


    public Mono<ServerResponse> findCustomer(ServerRequest request){
      int customerId= Integer.valueOf( request.pathVariable("input"));
       // dao.getCustomerList().filter(c->c.getId()==customerId).take(1).single();
        Mono<Customer> customerMono = dao.getCustomerList().filter(c -> c.getId() == customerId).next();
        return ServerResponse.ok().body(customerMono,Customer.class);
    }


    public Mono<ServerResponse> saveCustomer(ServerRequest request){
        Mono<Customer> customerMono = request.bodyToMono(Customer.class);
        Mono<String> saveResponse = customerMono.map(dto -> dto.getId() + ":" + dto.getName());
        return ServerResponse.ok().body(saveResponse,String.class);
    }
---------------End of second time----